<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Cl√©ment Jambon">
    <title>Cl√©ment Jambon</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üö¥‚Äç‚ôÇÔ∏è</text></svg>">

    <!-- <script type="text/javascript">
        profile_array = new Array();
        profile_array[0] = 'profile/profile1.jpg';
        profile_array[1] = 'profile/profile2.jpg';
        profile_array[2] = 'profile/profile3.jpg';
        profile_array[3] = 'profile/profile4.jpg';
        profile_array[4] = 'profile/profile5.jpg';
        profile_array[5] = 'profile/profile6.jpg';
        profile_array[6] = 'profile/profile7.jpg';

        function getRandomImage() {
            var num = Math.floor(Math.random() * profile_array.length);
            var img = profile_array[num];
            document.getElementById("random-profile").innerHTML = ('<img style="width:100%;max-width:100%" alt="profile photo" src="images/' + img + '" class="hoverZoomLink">');
        }
    </script> -->
    <link rel="stylesheet" href="./splats/index.css">
    <script type="importmap">
        {
            "imports": {
                "playcanvas": "https://cdn.jsdelivr.net/npm/playcanvas@2.3.3/build/playcanvas.mjs",
                "viewerSettings": "./splats/settings.json"
            }
        }
    </script>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@playcanvas/web-components@0.1.11/dist/pwc.mjs"></script>

</head>

<!-- <body onload="getRandomImage()"> -->

<body>
    <section class="section">
        <div class="container">
            <h1 class="title">
                Cl√©ment Jambon üö¥‚Äç‚ôÇÔ∏è
            </h1>
            <div class="columns reverse-column-order is-vcentered">
                <div class="column">
                    <!-- <article class="message is-warning">
                    <div class="message-header">
                      <p>Announcement</p>
                    </div>
                    <div class="message-body">
                      I am currently looking for a <strong>research internship</strong> from September/October 2023 to February 2024. Feel free to reach out to me through any of the contact details below!
                    </div>
                </article>
                <div class="pb-8"></div> -->
                    <p class="description-p"> I am a PhD student at <a href="https://www.eecs.mit.edu/">MIT
                            EECS</a> in the <a href="https://adg.csail.mit.edu/">Algorithmic Design Group</a>,
                        advised by Prof.
                        <a href="https://people.csail.mit.edu/mina/">Mina Konakoviƒá Lukoviƒá</a>.
                        Before that, I visited the <a href="https://3d.snu.ac.kr/">3D Vision
                            Lab</a> of Seoul National University, üá∞üá∑ where I completed my master's thesis under the
                        supervision of
                        by Prof. <a href="https://3d.snu.ac.kr/members/">Young Min Kim</a> and Prof. <a
                            href="https://inf.ethz.ch/people/person-detail.sorkine.html">Olga Sorkine-Hornung</a>.
                        Even earlier, I was a research intern at <a href="https://research.nvidia.com/">NVIDIA
                            Research</a> under
                        the supervision of <a href="https://research.nvidia.com/person/thomas-muller">Thomas M√ºller</a>
                        and <a href="https://research.nvidia.com/person/merlin-nimier-david">Merlin Nimier-David</a>.
                    </p>
                    <div class="pb-4"></div>
                    <!-- <p class="description-p"> I recently graduated from <a href="https://ethz.ch/">ETH Z√ºrich</a>üá®üá≠
                        where I
                        followed a master of science. In the <a href="https://inf.ethz.ch/">Computer Science
                            Department</a>, I majored in
                        <i>Visual
                            and Interactive Computing</i> and minored in <i>Machine Learning</i>. Additionally, I
                        hold a postgraduate engineering degree from <a href="https://www.polytechnique.edu/">√âcole
                            polytechnique</a> in Paris üéì.
                    </p> -->
                    <div class="pb-4"></div>
                    <p class="description-p">I'm interested in computer graphics and its intersections with machine
                        learning. Previously, my research has focused on high-performance, generalizable, and
                        manipulable
                        neural rendering and generation techniques. These days, I'm exploring new algorithms and
                        representations to design objects ü™ë, robots ü§ñ, and materials üß© that can live in the real
                        world. Some of my recent interests also include computer-aided design,
                        computational fabrication, geometry processing, generative modeling, symmetries of all kinds,
                        and funky Monte
                        Carlo estimators üñ•Ô∏è.
                    </p>
                    <div class="pb-4"></div>
                    <p class="description-p">In my free time, I enjoy hiking ‚õ∞Ô∏è,
                        cycling up (and
                        down) steep hills üö¥, running with a compass and a map üó∫Ô∏è, swimming in freezing lakes and
                        rivers üèäüèª, reading books and research papers üìñ, watching international movies you've probably
                        never heard of üé•, and first and foremost talking and socializing üëã. So if you want to chat or
                        grab a beer, count me in! üçª
                    </p>
                    <div class="pb-4"></div>
                    <p style="text-align:center">
                        <a onclick="emailAlert()">Email</a> &nbsp/&nbsp
                        <a href="https://scholar.google.com/citations?user=fACZ9fcAAAAJ">Scholar</a> &nbsp/&nbsp
                        <a href="data/cv.pdf">CV</a> &nbsp/&nbsp
                        <a href="https://x.com/clementjambon">Twitter</a> &nbsp/&nbsp
                        <a href="https://bsky.app/profile/clementjambon.bsky.social">Bluesky</a> &nbsp/&nbsp
                        <a href="https://github.com/clementjambon/">Github</a> &nbsp/&nbsp
                        <a href="https://www.linkedin.com/in/clementjambon/">LinkedIn</a>
                    </p>

                    <script>
                        function emailAlert() {
                            alert("cjambon [at] mit [dot] edu");
                        }
                    </script>
                </div>
                <div class="column is-one-third">
                    <div class="image" id="random-profile" style="width:100%;max-width:100%">
                        <pc-app antialias="false" depth="false" high-resolution="true" stencil="false">
                            <pc-asset id="camera-controls"
                                src="https://cdn.jsdelivr.net/npm/playcanvas@2.3.1/scripts/esm/camera-controls.mjs"
                                preload></pc-asset>
                            <pc-asset id="ply" type="gsplat" src="./splats/scene.compressed.ply"></pc-asset>
                            <pc-scene>
                                <!-- Camera (with XR support) -->
                                <pc-entity name="camera root">
                                    <pc-entity name="camera">
                                        <pc-camera nearClip="0.01" farClip="1000" horizontalFov="true"
                                            tonemap="none"></pc-camera>
                                        <pc-scripts>
                                            <pc-script name="cameraControls"></pc-script>
                                        </pc-scripts>
                                    </pc-entity>
                                </pc-entity>
                                <!-- Light (for XR controllers) -->
                                <pc-entity name="light" rotation="35 45 0">
                                    <pc-light color="white" intensity="1.5"></pc-light>
                                </pc-entity>
                                <!-- Splat -->
                                <pc-entity name="splat" rotation="0 0 180">
                                    <pc-splat asset="ply"></pc-splat>
                                </pc-entity>
                            </pc-scene>
                        </pc-app>

                        <!-- Loading Indicator -->
                        <div id="loadingIndicator">Loading...</div>

                        <script type="module" src="./splats/index.js"></script>
                        <!-- <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"> -->
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container">
            <h1 class="title">Education</h1>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image">
                        <img src="images/logos/logo_mit.png" alt="logo-mit">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://www.mit.edu/">
                            <strong>MIT</strong>
                        </a>
                        <br>
                        <a href="https://www.csail.mit.edu/">Computer Science and Artificial
                            Intelligence Laboratory</a>
                        <br>
                        PhD program
                        <br>
                        Supervised by Prof.
                        <a href="https://people.csail.mit.edu/mina/">Mina Konakoviƒá Lukoviƒá</a> in the <a
                            href="https://adg.csail.mit.edu/">Algorithmic Design Group</a>
                        <br>
                        <i>September 2024 - now</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image">
                        <img src="images/logos/logo_ethz.png" alt="logo-ethz">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://ethz.ch/">
                            <strong>ETH Z√ºrich</strong>
                        </a>
                        <br>
                        <a href="https://inf.ethz.ch/">Department of Computer Science</a>
                        <br>
                        Master of Science
                        <br>
                        Major in Visual and Interactive Computing, Minor in Machine Learning
                        <br>
                        <i>September 2022 - August 2024</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image">
                        <img src="images/logos/logo_x.png" alt="logo-polytechnique">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://www.polytechnique.edu/">
                            <strong>√âcole polytechnique</strong>
                        </a>
                        <br>
                        <a href="https://portail.polytechnique.edu/informatique/">Department of Computer Science</a>
                        <br>
                        Postgraduate engineering degree
                        <br>
                        Major in Image, Vision and Learning
                        <br>
                        <i>September 2019 - August 2023</i>
                    </p>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container">
            <h1 class="title">Publications</h1>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div id="brep-teaser" class="image" style="margin: auto;">
                        <img src="images/brep_teaser.png" alt="brep-teaser">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="#"><strong>BrepDiff: Single-stage B-rep Diffusion Model</strong></a> (SIGGRAPH 2025)
                        <br>
                        Mingi Lee<sup>*</sup>,
                        <a href="https://dszhang.me/about">Dongsu Zhang<sup>*</sup></a>,
                        <strong>Cl√©ment Jambon<sup>*</sup></strong>,
                        <a href="https://3d.snu.ac.kr/members/">Young Min Kim</a>
                        <br>
                        <i>BrepDiff</i> is a simple, single-stage diffusion model for generating Boundary
                        Representations (B-reps). It generates B-reps by denoising point-based face samples with a
                        dedicated noise schedule. Unlike multi-stage methods, BrepDiff enables intuitive, editable
                        geometry creation, including completion, merging, and interpolation, while achieving competitive
                        performance on unconditional generation.
                        <br>
                        <strong>Coming Soon!</strong>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <video width=100% muted autoplay loop>
                        <source src="images/nerfshop-teaser.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="column">
                    <p>
                        <a href="https://repo-sam.inria.fr/fungraph/nerfshop/"><strong>NeRFshop: Interactive Editing of
                                Neural Radiance Fields</strong></a> (I3D 2023)
                        <br>
                        <strong>Cl√©ment Jambon</strong>,
                        <a href="https://www.cg.tuwien.ac.at/staff/BernhardKerbl">Bernhard Kerbl</a>,
                        <a href="https://grgkopanas.github.io/">Georgios Kopanas</a>,
                        <a href="https://scholar.google.com/citations?user=uRSdPokAAAAJ&hl=en">Stavros Diolatzis</a>,
                        <a href="https://people.mpi-inf.mpg.de/~tleimkue/">Thomas Leimk√ºhler</a>,
                        <a href="http://www-sop.inria.fr/members/George.Drettakis/">George Drettakis</a>
                        <br>
                        <i>NeRFshop</i> is an end-to-end method that allows users to interactively select and
                        deform objects through cage-based transformations within NeRFs. Once complete, edits can be
                        collapsed and
                        saved as a portable NeRF representation through a distillation process.
                        <br>
                        <a href="https://repo-sam.inria.fr/fungraph/nerfshop/">Project page</a>
                        |
                        <a href="http://www-sop.inria.fr/reves/Basilic/2023/JKKDLD23/nerfshop.pdf">Paper</a>
                        |
                        <a href="https://youtu.be/HC56Zwui1bY">Video</a>
                        |
                        <a href="https://youtu.be/5hg5orogFf4?si=LFUgk-UhBlhjZwuF&t=70">Talk</a>
                        |
                        <a
                            href="https://docs.google.com/presentation/d/1jyz1kll2x-otdLzToJItyZT1RN4WvYiZykawr4Akumc/edit?usp=sharing">Slides</a>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <video width=100% muted autoplay loop>
                        <source src="images/neural-catacaustics.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div class="column">
                    <p>
                        <a href="https://repo-sam.inria.fr/fungraph/neural_catacaustics/"><strong>Neural Point
                                Catacaustics for Novel-View Synthesis of Reflections</strong></a> (SIGGRAPH Asia 2022)
                        <br>
                        <a href="https://grgkopanas.github.io/">Georgios Kopanas</a>,
                        <a href="https://people.mpi-inf.mpg.de/~tleimkue/">Thomas Leimk√ºhler</a>,
                        <a href="https://scholar.google.com/citations?user=uRSdPokAAAAJ&hl=en">Gilles Reiner</a>,
                        <strong>Cl√©ment Jambon</strong>,
                        <a href="http://www-sop.inria.fr/members/George.Drettakis/">George Drettakis</a>
                        <br>
                        <i>Neural Point Catacaustics</i> is a new point-based representation that allows novel-view
                        synthesis of scenes with curved reflectors, from a set of casually-captured
                        input.
                        <br>
                        <a href="https://repo-sam.inria.fr/fungraph/neural_catacaustics/">Project page</a>
                        |
                        <a
                            href="https://repo-sam.inria.fr/fungraph/neural_catacaustics/neural-catacaustics_small.pdf">Paper</a>
                        |
                        <a href="https://www.youtube.com/watch?v=YJiJg3q7Hqw&feature=emb_title">Video</a>
                    </p>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container">
            <h1 class="title">Experience</h1>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div id="logo-3dv" class="image" style="margin: auto;">
                        <img src="images/logos/logo_3dv.png" alt="logo-3dv">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://3d.snu.ac.kr/">
                            <strong>3D Vision Lab</strong>
                        </a>
                        <br>
                        Visiting Research Student
                        <br>
                        Supervisor: <a href="https://3d.snu.ac.kr/members/">Young Min Kim</a>
                        <br>
                        <i>February 2024 - August 2024</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div id="logo-nvidia" class="image" style="margin: auto;">
                        <img src="images/logos/logo_nvidia.png" alt="logo-nvidia">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://research.nvidia.com/">
                            <strong>NVIDIA</strong>
                        </a>
                        <br>
                        Research Intern
                        <br>
                        Supervisors: <a href="https://research.nvidia.com/person/thomas-muller">Thomas M√ºller</a> and <a
                            href="https://research.nvidia.com/person/merlin-nimier-david">Merlin Nimier-David</a>
                        <br>
                        <i>October 2023 - February 2024</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image">
                        <img src="images/logos/logo_inria_graphdeco.png" alt="logo-inria">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://inria.fr/">
                            <strong>Inria</strong>
                        </a>
                        -
                        <a href="https://team.inria.fr/graphdeco/">GraphDeco Team</a>
                        <br>
                        Research Intern
                        <br>
                        Supervisor: <a href="http://www-sop.inria.fr/members/George.Drettakis/">George Drettakis</a>
                        <br>
                        <i>March 2022 - August 2022</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image is-128x128" style="margin: auto;">
                        <img src="images/logos/logo_wemap.png" alt="logo-wemap">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://getwemap.com/">
                            <strong>Wemap</strong>
                        </a>
                        <br>
                        Computer Vision Engineer (Internship)
                        <br>
                        Supervisor: <a href="https://www.linkedin.com/in/michelthibaud/">Thibaud Michel</a>
                        <br>
                        <i>June 2021 - August 2021</i>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image is-128x128" style="margin: auto;">
                        <img src="images/logos/logo_itc.png" alt="logo-itc">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://itc.edu.kh/">
                            <strong>Institute of Technology of Cambodia</strong>
                        </a>
                        <br>
                        Teacher and Research Assistant (Internship)
                        <br>
                        <i>October 2019 - March 2020</i>
                    </p>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container">
            <h1 class="title">Projects</h1>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image is-128x128" style="margin: auto;">
                        <video width=100% muted autoplay loop>
                            <source src="images/flower-attention.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="data/report_diffusion_nerf.pdf"><strong>Improved 3D scene reconstruction with diffusion
                                models</strong></a> (ETH Z√ºrich)
                        <br>
                        <i>Semester project supervised by <a href="https://www.silvanweder.com/">Silvan Weder</a> among
                            the <a href="https://cvg.ethz.ch/">Computer Vision and Geometry Lab</a></i>
                        <br>
                        During 5 months, I investigated large-scale 2D diffusion models in order to perform "neural
                        extrapolations" of partial NeRF scenes. To tackle this problem, I mostly focused on the
                        following state-of-the-art techniques: Feature Fields, Score Distillation Sampling (SDS) and
                        feature-guided conditioning of diffusion models.
                        <br>
                        <a href="data/report_diffusion_nerf.pdf">Report (71.7 MB)</a>
                        |
                        <a href="data/report_diffusion_nerf_low.pdf">Low-res report (9.7 MB)</a>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image is-128x128" style="margin: auto;">
                        <img src="images/evolutionary_segmentation.png">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://github.com/clementjambon/evolutionary-segmentation"><strong>Game Theory for
                                Image Segmentation</strong></a> (ETH Z√ºrich)
                        <br>
                        For the block course <a href="https://coss.ethz.ch/education/controversies.html">Controversies
                            in Game Theory IX: Cooperative and Non-Cooperative Game Theory</a>, I reproduced results
                        from two previous works and implemented from scratch a segmentation algorithm based on game
                        theory and evolutionary dynamics. Additionally, I investigated the use of DINO features for
                        semantic segmentation.
                        <br>
                        <a href="https://github.com/clementjambon/evolutionary-segmentation">Code</a>
                        |
                        <a
                            href="https://raw.githubusercontent.com/clementjambon/evolutionary-segmentation/main/report.pdf">Report</a>
                    </p>
                </div>
            </div>
            <div class="pb-4"></div>
            <div class="columns box">
                <div class="column is-one-quarter">
                    <div class="image">
                        <img src="images/cg_rendering_competition.png">
                    </div>
                </div>
                <div class="column">
                    <p>
                        <a href="https://cgl.ethz.ch/teaching/cg22/competition/competition.php"><strong>Computer
                                Graphics 2022: Rendering Competition</strong></a> (ETH Z√ºrich)
                        <br>
                        <i>Honorable Mention of the jury</i>
                        <br>
                        For the Computer Graphics 2022 Rendering Competition at ETH Z√ºrich, <a
                            href="https://www.linkedin.com/in/marius-debussche/">Marius Debussche</a> and I implemented
                        a path tracer with complex features including spectral rendering, subsurface scattering, an
                        advanced camera model and participating media.
                    </p>
                </div>
            </div>
        </div>
    </section>
</body>

</html>